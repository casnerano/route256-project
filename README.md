# Route256 Project

## Задание 1

- Создать скелеты сервисов `cart` и `loms`, согласно [документации](docs/README.md).
- Структуру проекта сделать с учетом разбиения на слои, бизнес-логику писать отвязанной от реализаций клиентов и хендлеров.
- Все хендлеры отвечают просто заглушками.
- Все межсервисные вызовы выполняются. Если хендлер по описанию из [документации](docs/README.md) должен ходить в другой сервис, он должен у вас это успешно делать в коде.
- Должны успешно проходить `make precommit` и `make run-all` в корневой папке.
- Наладить общение с `product-service` (в хендлерах `cart.item.add`, `cart.list`). Токен авторизации брать из запроса и пробрасывать в контекст.
  
**Задания со звездочкой**:
- На алмаз реализовать in-memory хранилище для сервисов `cart` и `loms`;

## Задание 2
Перевести всё взаимодействие c сервисами на протокол `gRPC`.
Для этого:
- Создать `protobuf` контракты сервисов
- В каждом проекте нужно добавить в `Makefile` команды для генерации `.go` фалйло из `proto` файлов и установки нужных зависимостей (можно использовать `protoc` или `buf` на на свое усмотрение).
- Сгенерировать клиентов и сервисы
- Использовать разделение на слои, созданное ранее, заменив слой `HTTP` на `GRPC`.
- Взаимодействие по `HTTP` полностью удалить и оставить только `gRPC`.

**Задания со звездочкой**:
- Добавить `HTTP-gateway` и валидацию `protobuf` сообщений.
- Добавить `swagger-ui` и возможность совершать запросы из сваггера к сервису (поднять `swagger-ui` сервер).

## Задание 3

- Для каждого сервиса(где необходимо что-то сохранять/брать) поднять отдельную БД в `docker-compose`.
- Сделать миграции в каждом сервисе (достаточно папки миграций и скрипта).
- Создать необходимые таблицы.
- Реализовать логику репозитория в каждом сервисе. (Рекомендуется использовать `plain sql`, без query билдеров, однако приветствуется генерация по типу `sqlc`)
- Драйвер для работы с `postgresql`: только `pgx (pool)`.
- В одном из сервисов сделать транзакционность запросов (как на воркшопе).

**Задания со звездочкой**:
- Для каждой БД полнять свой балансировщик (`pgbouncer` или `odyssey`, можно и то и то). Сервисы ходят не на прямую в БД, а через балансировщик.

## Задание 4:
- Необходимо уменьшить время ответа `cart.List` при помощи конкурентности. К этой части задания есть следующие требования:
   - Для решения обязательно надо написать какую-либо собственную имплементацию конкурентного паттерна/структуры. Намеренно не ограничиваем в выборе, оригинальные идеи приветствуются. Логичной структурой будет Worker Pool
   - Вся имплементация обязательно должна быть покрыта комментариями о том, как она работает и на какие гарантии в каких местах вы рассчитываете. Это улучшит ваше понимание паттернов и одновременно облегчит работу тьюторов
- Во внешних походах к `Product Service` необходимо ограничить рейт запросов, т.е. настроить рейт-лимитер. Рейт-лимитер обязательно сделать в виде grpc интерцептора. Ограничить надо именно общее кол-во походов в единицу времени, а не одновременное кол-во активных запросов. Target RPS - `10 RPS`.
- В приложениях по всем слоям необходимо прокинуть контексты. Все контексты в рамках одного запроса должны быть связаны

**Задания со звездочкой**:
- Сделать аннулирование заказов старше 10 минут в фоне через горутину, не отдельный процесс-демон
- Синхронизировать рейт-лимитер внешних походов через единую сущность (в т.ч. между различными подами). В качестве внешнего хранилища можно использовать как `Postgres`, так и `Redis` (или любое другое хранилище, с которым вам комфортно работать)

## Задание 5:

Необходимо обеспечить покрытие логики ручек сервиса (`cart` или `loms`) модульными тестами. Общий уровень покрытия сервиса (по `statements`) должнен составлять не менее 70%.
Генерацию моков осуществлять любыми удобными средствами (`mockery`, `minimock`, `gomock`, etc...).

**Задания со звездочкой**:
- Добавить интеграционные тесты для проверки взаимодействия с базой данных для сервиса (`cart` или `loms`). Интеграционные тесты (и развертывание тестового окружения) должны запускаться при помощи скрипта.

## Задание №6

- Развернуть `kafka` кластер в `docker-compose`.
- Интегрировать `LOMS` с кафкой: `LOMS` пишет в кафку изменения статуса заказа (создание/отмена).
- Создать сервис нотификаций (просто main с консьюмер группой достаточно). Сервис нотификаций должен вычитывать сообщения о статусе заказа и отправлять нотификации об изменениях статуса заказа (просто писать в лог сообщение с номером заказа и статусом).
- Обеспечить гарантию отправки сообщения о статусе заказа (отказоустойчевый кластер/реплики, ack и вот это все).
- Обеспечить упорядоченную обработку статусов одного заказа (добиться упорядоченной отправки событий по заказу и чтение событий по заказу).
- Обеспечить семантику `exactly-once`.
   
**Задания со звездочкой**:
- Применить паттерн Outbox.